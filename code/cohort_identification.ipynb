{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eligibility for mobilization: Cohort ID and Discretizing script\n",
    "\n",
    "This script identifies the cohort using CLIF 2.0 tables and discretizes the dataset at an hourly level\n",
    "\n",
    " \n",
    "                        ðŸš¨Code will break if the following requirements are not satisfiedðŸš¨  \n",
    "#### Requirements:\n",
    "* Required table filenames should be `clif_patient`, `clif_hospitalization`, `clif_adt`, `clif_vitals`, `clif_labs`, `clif_medication_admin_continuous`, `clif_respiratory_support`\n",
    "* Within each table, the following variables and categories are required.\n",
    "\n",
    "| Table Name | Required Variables | Required Categories |\n",
    "| --- | --- | --- |\n",
    "| **patient** | `patient_id`, `race_category`, `ethnicity_category`, `sex_category` | - |\n",
    "| **hospitalization** | `patient_id`, `hospitalization_id`, `admission_dttm`, `discharge_dttm`, `age_at_admission` | - |\n",
    "| **vitals** | `hospitalization_id`, `recorded_dttm`, `vital_category`, `vital_value` | 'heart_rate', 'resp_rate', 'sbp', 'dbp', 'map', 'spo2' |\n",
    "| **labs** | `hospitalization_id`, `lab_result_dttm`, `lab_category`, `lab_value` | 'lactate' |\n",
    "| **medication_admin_continuous** | `hospitalization_id`, `admin_dttm`, `med_name`, `med_category`, `med_dose`, `med_dose_unit` | \"norepinephrine\", \"epinephrine\", \"phenylephrine\", \"vasopressin\", \"dopamine\", \"angiotensin\", \"nicardipine\", \"nitroprusside\", \"clevidipine\", \"cisatracurium\" |\n",
    "| **respiratory_support** | `hospitalization_id`, `recorded_dttm`, `device_category`, `mode_category`, `tracheostomy`, `fio2_set`, `lpm_set`, `resp_rate_set`, `peep_set`, `resp_rate_obs` | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas numpy duckdb seaborn matplotlib plotly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyCLIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required columns and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'device_name',\n",
    "    'device_category',\n",
    "    'mode_name', \n",
    "    'mode_category',\n",
    "    'tracheostomy',\n",
    "    'fio2_set',\n",
    "    'lpm_set',\n",
    "    'resp_rate_set',\n",
    "    'peep_set',\n",
    "    'resp_rate_obs',\n",
    "    'tidal_volume_set'\n",
    "]\n",
    "\n",
    "vitals_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'vital_category',\n",
    "    'vital_value'\n",
    "]\n",
    "vitals_of_interest = ['heart_rate', 'respiratory_rate', 'sbp', 'dbp', 'map', 'spo2']\n",
    "\n",
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['lactate']\n",
    "\n",
    "meds_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'admin_dttm',\n",
    "    'med_name',\n",
    "    'med_category',\n",
    "    'med_dose',\n",
    "    'med_dose_unit'\n",
    "]\n",
    "meds_of_interest = [\n",
    "    'norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin',\n",
    "    'dopamine', 'angiotensin', 'nicardipine', 'nitroprusside',\n",
    "    'clevidipine', 'cisatracurium'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pyCLIF.load_data('clif_patient')\n",
    "hospitalization = pyCLIF.load_data('clif_hospitalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all _dttm variables to the same format\n",
    "patient = pyCLIF.standardize_datetime(patient)\n",
    "hospitalization = pyCLIF.standardize_datetime(hospitalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pyCLIF.remove_duplicates(patient, ['patient_id'], 'patient')\n",
    "hospitalization = pyCLIF.remove_duplicates(hospitalization, ['hospitalization_id'], 'hospitalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Number of unique encounters in the data: {pyCLIF.count_unique_encounters(hospitalization, 'hospitalization_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclusion Criteria:\n",
    "\n",
    "* Filter Admissions for 2018-01-01 to 2023-12-31\n",
    "* Encounters receiving invasive mechanical ventilation during this period\n",
    "* A cool off period of 4 hours after first intubation for analysis\n",
    "\n",
    "### Exclusion criteria:\n",
    "\n",
    "1. Encounters that were on vent for less than 2 hours\n",
    "2. Encounters that were on trach in the first 72 hours \n",
    "3. Encounters that received Cisatracurium for 4 hours or more within the first 72 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = hospitalization[\n",
    "    (hospitalization['admission_dttm'] >= '2018-01-01') &\n",
    "    (hospitalization['admission_dttm'] <= '2023-12-31') &\n",
    "    (hospitalization['age_at_admission'] >= 18)\n",
    "].reset_index(drop=True)[['hospitalization_id']].drop_duplicates()\n",
    "\n",
    "cohort_ids = cohort['hospitalization_id'].unique().tolist()\n",
    "print(f\"Number of unique encounters after filtering by date and age:\", cohort['hospitalization_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clif respiratory table for this cohort\n",
    "rst_filters = {\n",
    "    'hospitalization_id': cohort_ids\n",
    "}\n",
    "resp_support_raw = pyCLIF.load_data('clif_respiratory_support', columns=rst_required_columns, filters=rst_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_support = resp_support_raw.copy()\n",
    "resp_support['recorded_dttm'] = pd.to_datetime(resp_support['recorded_dttm'])\n",
    "resp_support['device_category'] = resp_support['device_category'].str.lower()\n",
    "resp_support['mode_category'] = resp_support['mode_category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Nick's Waterfall fill logic for respiratory support table\n",
    "# This can take time: 2 - 12 mins depending on data size\n",
    "processed_resp_support = pyCLIF.process_resp_support(resp_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the cohort on invasive mechanical ventilation \n",
    "columns_to_keep = [\n",
    "    'hospitalization_id', 'recorded_dttm', 'device_name','device_category',\n",
    "    'mode_name', 'mode_category' , 'tracheostomy',\n",
    "    'fio2_set', 'lpm_set', 'peep_set', \n",
    "    'resp_rate_obs', 'resp_rate_set'\n",
    "]\n",
    "\n",
    "ventilator_usage = processed_resp_support[processed_resp_support['device_category'].str.contains(\"imv\", case=False, na=False)]\n",
    "cohort_on_vent = ventilator_usage.merge(cohort, on='hospitalization_id', how='left')\n",
    "cohort_on_vent = cohort_on_vent[columns_to_keep]\n",
    "cohort_on_vent['on_vent'] = cohort_on_vent['device_category'].str.contains(\"imv\", case=False, na=False).astype(int)\n",
    "cohort_on_vent.loc[:, 'recorded_dttm'] = pd.to_datetime(cohort_on_vent['recorded_dttm'])\n",
    "cohort_on_vent = cohort_on_vent.sort_values(by=['hospitalization_id', 'recorded_dttm'])\n",
    "cohort_on_vent = cohort_on_vent[cohort_on_vent['on_vent'] == 1]\n",
    "\n",
    "\n",
    "# Apply thresholds and replace values outside these with NaN using .loc[]\n",
    "# UPDATE THIS TO USE CSV / JSON FROM OUTLIER DIRECTORY\n",
    "# cohort_on_vent.loc[:, 'fio2_set'] = cohort_on_vent['fio2_set'].where(cohort_on_vent['fio2_set'].between(0.21, 1, inclusive='both'), np.nan)\n",
    "# Calculate the mean of 'fio2_set', excluding NaN values\n",
    "fio2_mean = cohort_on_vent['fio2_set'].mean(skipna=True)\n",
    "print(\"FIO2_SET MEAN\", fio2_mean)\n",
    "# If the mean is greater than 1, divide 'fio2_set' by 100\n",
    "if fio2_mean > 1:\n",
    "    # Only divide values greater than 1 to avoid re-dividing already correct values\n",
    "    print(\"Updated fio2_set to be between 0.21 and 1\")\n",
    "    cohort_on_vent.loc[cohort_on_vent['fio2_set'] > 1, 'fio2_set'] = \\\n",
    "        cohort_on_vent.loc[cohort_on_vent['fio2_set'] > 1, 'fio2_set'] / 100\n",
    "\n",
    "cohort_on_vent.loc[:, 'fio2_set'] = cohort_on_vent['fio2_set'].where(cohort_on_vent['fio2_set'].between(0.21, 1, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'resp_rate_set'] = cohort_on_vent['resp_rate_set'].where(cohort_on_vent['resp_rate_set'].between(0, 60, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'peep_set'] = cohort_on_vent['peep_set'].where(cohort_on_vent['peep_set'].between(0, 50, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'resp_rate_obs'] = cohort_on_vent['resp_rate_obs'].where(cohort_on_vent['resp_rate_obs'].between(0, 100, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'lpm_set'] = cohort_on_vent['lpm_set'].where(cohort_on_vent['lpm_set'].between(0, 60, inclusive='both'), np.nan)\n",
    "\n",
    "cohort_on_vent['recorded_date'] = cohort_on_vent['recorded_dttm'].dt.date\n",
    "cohort_on_vent['recorded_hour'] = cohort_on_vent['recorded_dttm'].dt.hour\n",
    "\n",
    "print(f\"Number of unique encounters after filtering for ventilator usage: {cohort_on_vent['hospitalization_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_start_end = cohort_on_vent.groupby('hospitalization_id').agg(\n",
    "    vent_start_time=('recorded_dttm', 'min'),\n",
    "    vent_end_time=('recorded_dttm', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Exclude encounters where vent start time and end time is the same \n",
    "vent_start_end = vent_start_end[vent_start_end['vent_start_time'] != vent_start_end['vent_end_time']]\n",
    "print(f\"Number of unique encounters after filtering for ventilator usage: {vent_start_end['hospitalization_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required vitals\n",
    "vitals_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'vital_category': vitals_of_interest\n",
    "}\n",
    "vitals = pyCLIF.load_data('clif_vitals', columns=vitals_required_columns, filters=vitals_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals.value_counts('vital_category')\n",
    "## if you don't have MAP, we can calculate here- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first_vital_dttm and last_vital_dttm for each hospitalization_id \n",
    "# We use this as proxy for admission and discharge dttm to construct hourly sequence for each hospitalization\n",
    "vital_dttm_bounds = vitals.groupby('hospitalization_id')['recorded_dttm'].agg(['min', 'max']).reset_index()\n",
    "vital_dttm_bounds.columns = ['hospitalization_id', 'first_vital_dttm', 'last_vital_dttm']\n",
    "print(\"unique encounters in vitals\", pyCLIF.count_unique_encounters(vital_dttm_bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly sequence for the cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort = vent_start_end.merge(vital_dttm_bounds, on='hospitalization_id', how='inner')\n",
    "print(\"unique encounters in resp filtered\", pyCLIF.count_unique_encounters(final_cohort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - last recorded vital shouldn't be less than vent start time\n",
    "# if this happens, check your CLIF tables bro\n",
    "cases_before_vent_start = final_cohort[final_cohort['last_vital_dttm'] < final_cohort['vent_start_time']]\n",
    "print(\"Cases where last vital dttm is before vent_start time:\", len(cases_before_vent_start))\n",
    "cases_before_vent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save IDs in this cohort to filter other tables\n",
    "cohort_ids = final_cohort['hospitalization_id'].unique().tolist()\n",
    "print(\"total number of unique hospitalizations in the identified cohort\", len(cohort_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate hourly sequence for each group (hospitalization_id)\n",
    "def generate_hourly_sequence(group):\n",
    "    # Get the vent start time and discharge time\n",
    "    start_time = group['vent_start_time'].iloc[0]\n",
    "    end_time = group['last_vital_dttm'].iloc[0]\n",
    "    \n",
    "    # Generate the sequence of hourly timestamps\n",
    "    hourly_timestamps = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "    \n",
    "    # Create a new DataFrame for this sequence\n",
    "    return pd.DataFrame({\n",
    "        'hospitalization_id': group['hospitalization_id'].iloc[0],\n",
    "        'recorded_dttm': hourly_timestamps\n",
    "    })\n",
    "\n",
    "# Apply the function to each group and concatenate the results\n",
    "hour_sequence = final_cohort.groupby('hospitalization_id')\\\n",
    "    .apply(generate_hourly_sequence)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "# Add `recorded_date` and `recorded_hour` columns\n",
    "# Convert recorded_dttm to datetime sanity check\n",
    "hour_sequence['recorded_dttm'] = pd.to_datetime(hour_sequence['recorded_dttm'])\n",
    "hour_sequence['recorded_date'] = hour_sequence['recorded_dttm'].dt.date\n",
    "hour_sequence['recorded_hour'] = hour_sequence['recorded_dttm'].dt.hour\n",
    "hour_sequence = hour_sequence.drop('recorded_dttm', axis=1)\n",
    "hour_sequence = hour_sequence.drop_duplicates()\n",
    "hour_sequence['time_from_vent'] = hour_sequence.groupby('hospitalization_id').cumcount()\n",
    "## add a cool off period of 4 hours after first intubation\n",
    "hour_sequence['time_from_vent_adjusted'] = hour_sequence['time_from_vent'].apply(lambda x: x - 4 if x >= 4 else -1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHOULDN'T HAVE ANY DUPLICATES\n",
    "hour_sequence_check = pyCLIF.remove_duplicates(hour_sequence, ['hospitalization_id', 'recorded_date', 'recorded_hour'], 'hour_sequence_check')\n",
    "del hour_sequence_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Respiratory support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_vent_df = cohort_on_vent.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour']).agg(\n",
    "    min_resp_rate_obs=pd.NamedAgg(column='resp_rate_obs', aggfunc='min'),\n",
    "    min_lpm_set=pd.NamedAgg(column='lpm_set', aggfunc='min'),\n",
    "    min_fio2_set=pd.NamedAgg(column='fio2_set', aggfunc='min'),\n",
    "    min_peep_set=pd.NamedAgg(column='peep_set', aggfunc='min'),\n",
    "    max_resp_rate_obs=pd.NamedAgg(column='resp_rate_obs', aggfunc='max'),\n",
    "    max_lpm_set=pd.NamedAgg(column='lpm_set', aggfunc='max'),\n",
    "    max_fio2_set=pd.NamedAgg(column='fio2_set', aggfunc='max'),\n",
    "    max_peep_set=pd.NamedAgg(column='peep_set', aggfunc='max'),\n",
    "    hourly_trach=pd.NamedAgg(column='tracheostomy', aggfunc=lambda x: 1 if x.max() == 1 else 0),\n",
    "    hourly_on_vent=pd.NamedAgg(column='on_vent', aggfunc=lambda x: 1 if x.max() == 1 else 0)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hourly_vent_df with hour_sequence on hospitalization_id, recorded_date, and recorded_hour\n",
    "final_df = pd.merge(hour_sequence, hourly_vent_df, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                     how='left')\n",
    "print(\"unique encounters who were ever on vent (before applying exclusion criteria)\", pyCLIF.count_unique_encounters(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total hours on vent for each encounter within the first 72 hours\n",
    "first_72_hours = hour_sequence[(hour_sequence['time_from_vent_adjusted'] >= 0) & (hour_sequence['time_from_vent_adjusted'] < 72)]\n",
    "final_df_72 = pd.merge(first_72_hours, hourly_vent_df, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                     how='left')\n",
    "vent_hours_per_encounter = final_df_72.groupby('hospitalization_id')['hourly_on_vent'].sum()\n",
    "# Identify encounters with less than 2 hours on vent\n",
    "encounters_less_than_2_hours = vent_hours_per_encounter[vent_hours_per_encounter <= 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude those encounters that were on the vent for less than 2 hours in the first 72 hours\n",
    "final_df = final_df[~final_df['hospitalization_id'].isin(encounters_less_than_2_hours)]\n",
    "print(\"\\n encounters that were on the vent for less than 2 hours in the first 72 hours\", len(encounters_less_than_2_hours))\n",
    "print(\"\\n unique encounters after excluding encounters on vent for 2 hrs or less\", pyCLIF.count_unique_encounters(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude encounters with tracheostomy in the first 72 hours\n",
    "# Identify encounters with trach in the first 72 hours\n",
    "encounters_with_trach = final_df_72.groupby('hospitalization_id')['hourly_trach'].max()\n",
    "# Identify encounters where trach is present\n",
    "encounters_with_trach = encounters_with_trach[encounters_with_trach == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude encounters with trach in the first 72 hours\n",
    "final_df = final_df[~final_df['hospitalization_id'].isin(encounters_with_trach)]\n",
    "print(\"\\n encounters with trach in the first 72 hours\", len(encounters_with_trach))\n",
    "print(\"\\n unique encounters after excluding encounters on trach during the first 72 hours\", pyCLIF.count_unique_encounters(final_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Meds\n",
    "\n",
    "* Exclude encounters that are on cisatracurium for more than 4 hours within the first 72 hours\n",
    "* Calculate NE equivalent levels using \"norepinephrine\", \"epinephrine\", \"phenylephrine\", \"vasopressin\", \"dopamine\",  \"angiotensin\"\n",
    "* Create flags for \"nicardipine\", \"nitroprusside\", \"clevidipine\" for the red criteria under consensus criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clif continuous meds for the cohort on vent during the required time period\n",
    "meds_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'med_category': meds_of_interest\n",
    "}\n",
    "meds = pyCLIF.load_data('clif_medication_admin_continuous', columns=meds_required_columns, filters=meds_filters)\n",
    "print(\"unique encounters in meds\", pyCLIF.count_unique_encounters(meds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds['admin_dttm'] = pd.to_datetime(meds['admin_dttm'], format='%Y-%m-%d %H:%M:%S')\n",
    "meds['med_dose'] = pd.to_numeric(meds['med_dose'], errors='coerce')\n",
    "# Create 'date' and 'hour_of_day' columns\n",
    "meds['recorded_date'] = meds['admin_dttm'].dt.date\n",
    "meds['recorded_hour'] = meds['admin_dttm'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude encounters that are on cisatracurium for more than 4 hours within the first 72 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'admin_dttm' is in datetime format\n",
    "cisatracurium_filtered = meds[meds['med_category'].str.contains(\"cisatracurium\", case=False, na=False)].drop_duplicates()\n",
    "# Sort by 'hospitalization_id' and 'admin_dttm'\n",
    "cisatracurium_filtered = cisatracurium_filtered.sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "\n",
    "# Merge with vent_start_end to get vent_start_time\n",
    "cisatracurium_filtered = cisatracurium_filtered.merge(\n",
    "    final_df_72[['hospitalization_id', 'recorded_date', 'recorded_hour']], \n",
    "    on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Define the maximum allowed gap between doses (e.g., 1 hour)\n",
    "max_gap = pd.Timedelta(hours=1)\n",
    "\n",
    "# Function to identify continuous periods\n",
    "def identify_continuous_periods(group):\n",
    "    group = group.copy()\n",
    "    group['time_diff'] = group['admin_dttm'].diff()\n",
    "    group['new_period'] = (group['time_diff'] > max_gap) | (group['time_diff'].isna())\n",
    "    group['period_id'] = group['new_period'].cumsum()\n",
    "    return group\n",
    "\n",
    "# Apply the function to each 'hospitalization_id'\n",
    "cis_periods = cisatracurium_filtered.groupby('hospitalization_id').apply(identify_continuous_periods).reset_index(drop=True)\n",
    "\n",
    "# Calculate the duration of each continuous period\n",
    "period_durations = cis_periods.groupby(['hospitalization_id', 'period_id']).agg(\n",
    "    period_start=('admin_dttm', 'min'),\n",
    "    period_end=('admin_dttm', 'max')\n",
    ").reset_index()\n",
    "\n",
    "period_durations['period_duration'] = (\n",
    "    period_durations['period_end'] - period_durations['period_start']\n",
    ").dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "# Identify patients with any continuous period >= 4 hours\n",
    "cis_flag_df = period_durations.groupby('hospitalization_id').agg(\n",
    "    max_period_duration=('period_duration', 'max')\n",
    ").reset_index()\n",
    "\n",
    "cis_flag_df['cis_flag'] = (cis_flag_df['max_period_duration'] >= 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_with_cis = cis_flag_df[cis_flag_df['cis_flag'] == 1]['hospitalization_id'].drop_duplicates()\n",
    "final_df = final_df[~final_df['hospitalization_id'].isin(encounters_with_cis)]\n",
    "print(\"\\n encounters with cis for more than 4 hours  in the first 72 hours\", len(encounters_with_cis))\n",
    "print(\"\\n unique encounters after excluding encounters on trach during the first 72 hours\", pyCLIF.count_unique_encounters(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to aggregate min and max doses by medication and hour\n",
    "meds_list = [\n",
    "    \"norepinephrine\", \"epinephrine\", \"phenylephrine\", \n",
    "    \"vasopressin\", \"dopamine\",  \n",
    "    \"angiotensin\"\n",
    "]\n",
    "\n",
    "dose_ranges_df = pd.DataFrame({\n",
    "    'med_category': ['norepinephrine', 'epinephrine', 'phenylephrine', 'angiotensin', 'vasopressin', 'dopamine'],\n",
    "    'min_dose': [0.01, 0.01, 0.1, 20, 0, 2],\n",
    "    'max_dose': [3, 0.1, 5, 200, 5, 20]\n",
    "})\n",
    "\n",
    "ne_df = meds[meds['med_category'].isin(meds_list)].copy()\n",
    "# Merge the dose ranges into the meds DataFrame\n",
    "ne_df = pd.merge(ne_df, dose_ranges_df, on='med_category', how='left')\n",
    "\n",
    "# Apply the dose thresholds to filter out outliers\n",
    "ne_df_filtered = ne_df[\n",
    "    (ne_df['med_dose'] >= ne_df['min_dose']) & (ne_df['med_dose'] <= ne_df['max_dose'])\n",
    "]\n",
    "# Convert angiotensin II from ng/kg/min to mcg/kg/min\n",
    "ne_df.loc[ne_df['med_category'] == 'angiotensin', 'med_dose'] = ne_df.loc[ne_df['med_category'] == 'angiotensin', 'med_dose'] / 1000\n",
    "# ne_df.loc[ne_df['med_category'] == 'angiotensin', 'unit'] = 'mcg/kg/min'\n",
    "\n",
    "# Optionally, drop the min_dose and max_dose columns if no longer needed\n",
    "ne_df_filtered = ne_df_filtered.drop(columns=['min_dose', 'max_dose'])\n",
    "pivoted_med_df = ne_df_filtered.pivot_table(\n",
    "    index=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    columns='med_category',\n",
    "    values='med_dose',\n",
    "    aggfunc=['min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "pivoted_med_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in pivoted_med_df.columns]\n",
    "# Remove trailing underscores\n",
    "pivoted_med_df.columns = [col.rstrip('_') for col in pivoted_med_df.columns]\n",
    "\n",
    "# Calculate the NE dose using the available minimum columns\n",
    "## Norepinephrine equivalent calculation\n",
    "# Goradia S, Sardaneh AA, Narayan SW, Penm J, Patanwala AE. Vasopressor dose equivalence: \n",
    "# A scoping review and suggested formula. J Crit Care. 2021 Feb;61:233-240. doi: 10.1016/j.jcrc.2020.11.002. Epub 2020 Nov 14. PMID: 33220576.\n",
    "pivoted_med_df['ne_calc_min'] = (\n",
    "    pivoted_med_df['min_norepinephrine'].fillna(0) +\n",
    "    pivoted_med_df['min_epinephrine'].fillna(0) +\n",
    "    pivoted_med_df['min_phenylephrine'].fillna(0) / 10 +\n",
    "    pivoted_med_df['min_dopamine'].fillna(0) / 100 +\n",
    "    pivoted_med_df['min_vasopressin'].fillna(0) * 2.5 +\n",
    "    pivoted_med_df['min_angiotensin'].fillna(0) * 10\n",
    ")\n",
    "\n",
    "# Calculate the NE dose using the available maximum columns\n",
    "pivoted_med_df['ne_calc_max'] = (\n",
    "    pivoted_med_df['max_norepinephrine'].fillna(0) +\n",
    "    pivoted_med_df['max_epinephrine'].fillna(0) +\n",
    "    pivoted_med_df['max_phenylephrine'].fillna(0) / 10 +\n",
    "    pivoted_med_df['max_dopamine'].fillna(0) / 100 +\n",
    "    pivoted_med_df['max_vasopressin'].fillna(0) * 2.5 +\n",
    "    pivoted_med_df['max_angiotensin'].fillna(0) * 10\n",
    ")\n",
    "\n",
    "# Select the relevant columns\n",
    "ne_calc_df = pivoted_med_df[[\n",
    "    'hospitalization_id', 'recorded_date', 'recorded_hour',\n",
    "    'min_norepinephrine', 'max_norepinephrine',\n",
    "    'ne_calc_min', 'ne_calc_max'\n",
    "]].drop_duplicates(subset=['hospitalization_id', 'recorded_date', 'recorded_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, ne_calc_df, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_meds_list = [\n",
    "    \"nicardipine\", \"nitroprusside\", \"clevidipine\"\n",
    "]\n",
    "\n",
    "# Filter meds_filtered for the medications in red_meds_list\n",
    "red_meds_df = meds[meds['med_category'].isin(red_meds_list)].copy()\n",
    "\n",
    "# Create a flag for each medication in red_meds_list\n",
    "for med in red_meds_list:\n",
    "    # Create a flag that is 1 if the medication was administered in that hour, 0 otherwise\n",
    "    red_meds_df[med + '_flag'] = np.where(red_meds_df['med_category'] == med, 1, 0).astype(int)\n",
    "\n",
    "# Aggregate to get the maximum value for each flag (per hospitalization_id, recorded_date, recorded_hour)\n",
    "# This ensures that if the medication was administered even once in the hour, the flag is 1\n",
    "red_meds_flags = red_meds_df.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour']).agg(\n",
    "    {med + '_flag': 'max' for med in red_meds_list}\n",
    ").reset_index()\n",
    "\n",
    "#  combine all flags into a single 'red_meds_flag', you can do so like this:\n",
    "red_meds_flags['red_meds_flag'] = red_meds_flags[[med + '_flag' for med in red_meds_list]].max(axis=1)\n",
    "\n",
    "# Select the relevant columns\n",
    "red_meds_flags_final = red_meds_flags[[\n",
    "    'hospitalization_id', 'recorded_date', 'recorded_hour',\n",
    "    'nicardipine_flag', 'nitroprusside_flag',\n",
    "    'clevidipine_flag', 'red_meds_flag'\n",
    "]].drop_duplicates(subset=['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "\n",
    "red_meds_flags_final['nicardipine_flag'] = red_meds_flags_final['nicardipine_flag'].astype(int)\n",
    "red_meds_flags_final['nitroprusside_flag'] = red_meds_flags_final['nitroprusside_flag'].astype(int)\n",
    "red_meds_flags_final['clevidipine_flag'] = red_meds_flags_final['clevidipine_flag'].astype(int)\n",
    "red_meds_flags_final['red_meds_flag'] = red_meds_flags_final['red_meds_flag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, red_meds_flags_final, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals['recorded_dttm'] = pd.to_datetime(vitals['recorded_dttm'])\n",
    "vitals['recorded_hour'] = vitals['recorded_dttm'].dt.hour\n",
    "vitals['recorded_date'] = vitals['recorded_dttm'].dt.date\n",
    "\n",
    "vitals_min_max = vitals.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour', 'vital_category']).agg(\n",
    "    min=pd.NamedAgg(column='vital_value', aggfunc='min'),\n",
    "    max=pd.NamedAgg(column='vital_value', aggfunc='max')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the table to reshape it\n",
    "vitals_pivot = vitals_min_max.pivot_table(\n",
    "    index=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    columns='vital_category',\n",
    "    values=['min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the column multi-index after pivot\n",
    "vitals_pivot.columns = ['_'.join(col).strip() if type(col) is tuple else col for col in vitals_pivot.columns]\n",
    "# Remove trailing underscores\n",
    "vitals_pivot.columns = [col.rstrip('_') for col in vitals_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vitals with final_df\n",
    "final_df = pd.merge(final_df, vitals_pivot, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                   how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## confirm duplicates don't exist\n",
    "checkpoint_vitals = pyCLIF.remove_duplicates(final_df, [\n",
    "    'hospitalization_id','recorded_date', 'recorded_hour'\n",
    "], 'final_df')\n",
    "del checkpoint_vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Lab\n",
    "\n",
    "Get most recent lactate defined as closest lab result time to the start of first intubation event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clif continuous meds and clif labs table for the cohort on vent during the required time period\n",
    "labs_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'lab_category': labs_of_interest\n",
    "}\n",
    "labs = pyCLIF.load_data('clif_labs', columns=labs_required_columns, filters=labs_filters)\n",
    "print(\"unique encounters in labs\", pyCLIF.count_unique_encounters(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs['lab_result_dttm'] = pd.to_datetime(labs['lab_result_dttm'])\n",
    "labs['recorded_hour'] = labs['lab_result_dttm'].dt.hour\n",
    "labs['recorded_date'] = labs['lab_result_dttm'].dt.date\n",
    "\n",
    "lactate_df = pd.merge(labs, vent_start_end, on='hospitalization_id', how='left')\n",
    "lactate_df['time_since_vent_start_hours'] = (\n",
    "    (lactate_df['lab_result_dttm'] - lactate_df['vent_start_time']).dt.total_seconds() / 3600\n",
    ")\n",
    "\n",
    "# Calculate the absolute time difference between lab_result_dttm and vent_start_time in hours\n",
    "lactate_df['time_diff_hours'] = abs((lactate_df['lab_result_dttm'] - lactate_df['vent_start_time']).dt.total_seconds() / 3600)\n",
    "\n",
    "# Filter for observations within the first 72 hours since vent_start_time\n",
    "# lactate_df = lactate_df[(lactate_df['time_since_vent_start_hours'] >= 0) & \n",
    "#                         (lactate_df['time_since_vent_start_hours'] <= 72)]\n",
    "\n",
    "# Sort by hospitalization_id, recorded_hour, and time_diff_hours to find the closest measurement to vent_start_time\n",
    "lactate_df = lactate_df.sort_values(by=['hospitalization_id', 'recorded_date', 'recorded_hour', 'time_diff_hours'])\n",
    "\n",
    "# Group by hospitalization_id and recorded_hour, and get the first row in each group (which is the closest measurement)\n",
    "# closest lactate measurement is defined as closest to the vent_start_time in that hour. \n",
    "closest_lactate_df = lactate_df.groupby(['hospitalization_id', 'recorded_date','recorded_hour']).first().reset_index()\n",
    "\n",
    "labs_final = closest_lactate_df[['hospitalization_id', 'recorded_date', 'recorded_hour', 'lab_value_numeric']].copy()\n",
    "\n",
    "# Rename the 'lab_value_numeric' column to 'lactate'\n",
    "labs_final = labs_final.rename(columns={'lab_value_numeric': 'lactate'})\n",
    "\n",
    "final_df = pd.merge(final_df, labs_final, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                   how='left')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_labs= pyCLIF.remove_duplicates(final_df, [\n",
    "    'hospitalization_id', 'recorded_date', 'recorded_hour'\n",
    "], 'final_df')\n",
    "del checkpoint_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write analysis dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet('../output/intermediate/final_df.parquet')\n",
    "final_df['hospitalization_id'].to_csv('../output/intermediate/cohort_ids.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mobilization)",
   "language": "python",
   "name": ".mobilization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
