{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eligibility for mobilization - Analysis\n",
    "\n",
    "Run this script after running the [cohort_identification.ipynb](cohort_identification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas numpy duckdb seaborn matplotlib tableone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import pyCLIF\n",
    "from tableone import TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_parquet('../output/intermediate/final_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Backward fill the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to fill NAs\n",
    "# Columns not to fill\n",
    "exclude_columns = ['hospitalization_id', 'recorded_date', 'recorded_hour', 'time_from_vent', 'time_from_vent_adjusted']\n",
    "\n",
    "# List of columns to fill NAs (all columns except the excluded ones)\n",
    "columns_to_fill = [col for col in final_df.columns if col not in exclude_columns]\n",
    "\n",
    "# Fill NAs forward and backward by hospitalization_id\n",
    "final_df[columns_to_fill] = final_df.groupby('hospitalization_id')[columns_to_fill].transform(\n",
    "    lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
    ")\n",
    "\n",
    "# Set 'hospitalization_id' to object (string)\n",
    "final_df['hospitalization_id'] = final_df['hospitalization_id'].astype(str)\n",
    "\n",
    "# Convert 'recorded_date' to datetime\n",
    "final_df['recorded_date'] = pd.to_datetime(final_df['recorded_date']).dt.date\n",
    "\n",
    "# Replace NAs with 0 for med flags columns\n",
    "final_df[['red_meds_flag']] = final_df[['red_meds_flag']].fillna(0)\n",
    "# Columns to set as int64\n",
    "int64_columns = [\n",
    "    'recorded_hour',\n",
    "    'time_from_vent',\n",
    "    'time_from_vent_adjusted',\n",
    "    'hourly_trach',\n",
    "    'hourly_on_vent',\n",
    "    'red_meds_flag'\n",
    "]\n",
    "\n",
    "# Convert specified columns to int64\n",
    "final_df[int64_columns] = final_df[int64_columns].astype('int64')\n",
    "\n",
    "# Set all other variables to float64\n",
    "exclude_columns_for_float = ['hospitalization_id', 'recorded_date'] + int64_columns\n",
    "float64_columns = [col for col in final_df.columns if col not in exclude_columns_for_float]\n",
    "final_df[float64_columns] = final_df[float64_columns].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint- useful to compare to the original df and check filling logic\n",
    "final_df.to_parquet(f'../output/intermediate/final_df_filled_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Criteria Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patel et al. Criteria:\n",
    "\n",
    "Cardio\n",
    "* Mean arterial blood pressure: 65-110 mm Hg\n",
    "* Systolic blood pressure: ≤ 200 mm Hg\n",
    "* Heart rate: 40-130 beats per minute\n",
    "\n",
    "Respiratory\n",
    "* Respiratory rate: 5-40 breaths per minute\n",
    "* Pulse oximetry: ≥ 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head( n =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the DataFrame is sorted by 'hospitalization_id' and 'time_from_vent'\n",
    "final_df = final_df.sort_values(by=['hospitalization_id', 'time_from_vent'])\n",
    "\n",
    "# Define a function to calculate the rolling minimum and fill NaN values\n",
    "def rolling_min(group):\n",
    "    group['min_ne_dose_last_6_hours'] = group['ne_calc_max'].rolling(window=6, min_periods=1).min()\n",
    "    group['min_ne_dose_last_6_hours'] = group['min_ne_dose_last_6_hours'].fillna(method='ffill').fillna(0)\n",
    "    return group\n",
    "\n",
    "# Apply the rolling minimum function to each group\n",
    "final_df = final_df.groupby('hospitalization_id').apply(rolling_min).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Patel et al. Criteria\n",
    "\n",
    "# 1. Mean arterial blood pressure: 65-110 mm Hg\n",
    "final_df['patel_map_flag'] = (\n",
    "    (final_df['min_map'] >= 65) & (final_df['max_map'] <= 110)\n",
    ").astype(int)\n",
    "\n",
    "# 2. Systolic blood pressure: ≤ 200 mm Hg\n",
    "final_df['patel_sbp_flag'] = (\n",
    "    final_df['max_sbp'] <= 200\n",
    ").astype(int)\n",
    "\n",
    "# 3. Heart rate (Pulse): 40-130 beats per minute\n",
    "final_df['patel_pulse_flag'] = (\n",
    "    (final_df['min_heart_rate'] >= 40) & (final_df['max_heart_rate'] <= 130)\n",
    ").astype(int)\n",
    "\n",
    "# 4. Respiratory rate: 5-40 breaths per minute\n",
    "final_df['patel_resp_rate_flag'] = (\n",
    "    (final_df['min_respiratory_rate'] >= 5) & (final_df['max_respiratory_rate'] <= 40)\n",
    ").astype(int)\n",
    "\n",
    "# 5. Pulse oximetry (SpO2): ≥ 88%\n",
    "final_df['patel_spo2_flag'] = (\n",
    "    final_df['min_spo2'] >= 88\n",
    ").astype(int)\n",
    "\n",
    "# Resp flag: Combines respiratory rate and SpO2 criteria\n",
    "final_df['patel_resp_flag'] = (\n",
    "    final_df['patel_resp_rate_flag'] &\n",
    "    final_df['patel_spo2_flag']\n",
    ").astype(int)\n",
    "\n",
    "# Cardio flag: Combines MAP, SBP, and Pulse criteria\n",
    "final_df['patel_cardio_flag'] = (\n",
    "    final_df['patel_map_flag'] &\n",
    "    final_df['patel_sbp_flag'] &\n",
    "    final_df['patel_pulse_flag']\n",
    ").astype(int)\n",
    "\n",
    "# Step 2: Create the overall Patel flag\n",
    "final_df['patel_flag'] = (\n",
    "    final_df['patel_map_flag'] &\n",
    "    final_df['patel_sbp_flag'] &\n",
    "    final_df['patel_pulse_flag'] &\n",
    "    final_df['patel_resp_rate_flag'] &\n",
    "    final_df['patel_spo2_flag']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM criteria\n",
    "\n",
    "Cardio\n",
    "* Heart rate: ≤ 150 bpm\n",
    "* Most recent lactate: ≤ 4.0 mmol/L\n",
    "* Noradrenaline infusion rate: <0.2 mcg/kg/min or if infusion rate has increased by more than 25% in the last 6 hours, dose must be <0.1 mcg/kg/min.\n",
    "Respiratory\n",
    "* Sufficient respiratory stability:\n",
    "    *  FiO2: ≤ 0.6\n",
    "    *  PEEP: ≤ 16 cm H2O (use peep_observed)\n",
    "* Current respiratory rate: ≤ 45 (use resp_rate_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Heart rate: ≤ 150 bpm\n",
    "final_df['team_pulse_flag'] = (\n",
    "    final_df['max_heart_rate'] <= 150\n",
    ").astype(int)\n",
    "\n",
    "# 2. Most recent lactate: ≤ 4.0 mmol/L\n",
    "final_df['team_lactate_flag'] = (\n",
    "    final_df['lactate'] <= 4.0\n",
    ").astype(int)\n",
    "\n",
    "# 3. Noradrenaline infusion rate: <0.2 mcg/kg/min \n",
    "final_df['team_ne_flag'] = (\n",
    "    # (final_df['ne_calc_min'] >= 0.1) & (final_df['ne_calc_max'] <= 0.2)\n",
    "    final_df['ne_calc_max'] <= 0.2\n",
    ").astype(int)\n",
    "\n",
    "# print the number of team_ne_flag == 1\n",
    "print(final_df['team_ne_flag'].value_counts())\n",
    " \n",
    "#3b. set the flag to 0 if infusion rate has increased by more than 25% in the last 6 hours and the dose is >0.1 mcg/kg/min.\n",
    "final_df['team_ne_flag'] = np.where(\n",
    "    (final_df['ne_calc_max'] > 1.25 * final_df['min_ne_dose_last_6_hours']) & (final_df['ne_calc_max'] > 0.1),\n",
    "    0,\n",
    "    final_df['team_ne_flag']\n",
    ")\n",
    "print(final_df['team_ne_flag'].value_counts())\n",
    "# 4. Sufficient respiratory stability:\n",
    "#    a. FiO2: ≤ 0.6\n",
    "final_df['team_fio2_flag'] = (\n",
    "    final_df['min_fio2_set'] <= 0.6\n",
    ").astype(int)\n",
    "\n",
    "#    b. PEEP: ≤ 16 cm H2O\n",
    "final_df['team_peep_flag'] = (\n",
    "    final_df['max_peep_set'] <= 16\n",
    ").astype(int)\n",
    "\n",
    "# 5. Current respiratory rate: ≤ 45\n",
    "final_df['team_resp_rate_flag'] = (\n",
    "    final_df['max_resp_rate_obs'] <= 45\n",
    ").astype(int)\n",
    "\n",
    "# Cardio flag: Combines heart rate, lactate, and norepinephrine criteria\n",
    "final_df['team_cardio_flag'] = (\n",
    "    final_df['team_pulse_flag'] &\n",
    "    final_df['team_lactate_flag'] &\n",
    "    final_df['team_ne_flag']\n",
    ").astype(int)\n",
    "\n",
    "# Resp flag: Combines FiO2, PEEP, and respiratory rate criteria\n",
    "final_df['team_resp_flag'] = (\n",
    "    final_df['team_fio2_flag'] &\n",
    "    final_df['team_peep_flag'] &\n",
    "    final_df['team_resp_rate_flag']\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# Step 2: Create the overall TEAM flag\n",
    "final_df['team_flag'] = (\n",
    "    final_df['team_pulse_flag'] &\n",
    "    final_df['team_lactate_flag'] &\n",
    "    final_df['team_ne_flag'] &\n",
    "    final_df['team_fio2_flag'] &\n",
    "    final_df['team_peep_flag'] &\n",
    "    final_df['team_resp_rate_flag']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus criteria\n",
    "\n",
    "* Green Criteria\n",
    "    * Respiratory\n",
    "        * Saturation  90% and\n",
    "        * Respiratory rate ≤ 30 breaths/min\n",
    "        * Current FiO2 ≤ 0.6 and\n",
    "        * PEEP≤ 10cm H20\n",
    "    * Cardiovascular:\n",
    "        * Blood pressure greater than lower limit of target range (MAP 65+) while on no or low level of support (low support- define as <0.1 μg/kg/min of Norepi equivalents)\n",
    "        * Heart rate <120 beats/min\n",
    "        * lactate < 4mmol/L\n",
    "        * HR > 40\n",
    "* Yellow Criteria\n",
    "    * Respiratory\n",
    "        * Sat >= 90%\n",
    "        * Current FiO2 >0.6\n",
    "        * Respiratory rate >30breaths/min\n",
    "        * PEEP >10cm H20\n",
    "    * Cardiovascular\n",
    "        * Blood pressure greater than lower limit of target range (MAP 65+) while receiving moderate level of support (medium-define as 0.1–0.3 μg/kg/min of Norepi equivalents)\n",
    "        * Heart rate 120-150 beats/min\n",
    "        * Shock of any cause with lactate >4mmol/L\n",
    "        * HR > 40\n",
    "* Red Criteria\n",
    "    * Respiratory\n",
    "        * Sat <90%\n",
    "    * Cardiovascular\n",
    "        * Below target MAP despite support (MAP <65) or\n",
    "        * greater than lower limit MAP (MAP 65+) but on high level support (high defined as >0.3 μg/kg/min of Norepi equivalents)\n",
    "        * IV therapy for hypertensive emergency (SBP >200mmHg or MAP >110 and on nicardipine, nitroprusside, or clevidipine gtt)\n",
    "        * HR >150 bpm\n",
    "        * Bradycardia <40\n",
    "\n",
    "\n",
    "### Consensus criteria - redefined \n",
    "\n",
    "* all_red: All red subcomponents must be met.\n",
    "* all_green: All green subcomponents must be met, and no red subcomponents are met.\n",
    "* all_yellow: All yellow subcomponents must be met, no red subcomponents are met, and all green subcomponents are not met.\n",
    "* any_yellow: Any yellow subcomponent is met, no green subcomponents are fully met, and no red subcomponents are met.\n",
    "* any_yellow_or_green_no_red: Any yellow or green subcomponents are met, but no red subcomponents are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Cardiovascular Criteria\n",
    "final_df['red_resp_spo2_flag'] = (final_df['min_spo2'] < 90).astype(int)\n",
    "final_df['red_map_flag'] = (final_df['min_map'] < 65).astype(int)\n",
    "# High support (Norepinephrine equivalents > 0.3 μg/kg/min)\n",
    "final_df['red_high_support_flag'] = (final_df['ne_calc_max'] > 0.3).astype(int)\n",
    "# Hypertensive emergency criteria (SBP > 200 mmHg or MAP > 110 mmHg and on certain medications)\n",
    "final_df['red_hypertensive_flag'] = (\n",
    "    ((final_df['max_sbp'] > 200) | (final_df['max_map'] > 110)) &\n",
    "    (final_df['red_meds_flag'] == 1)\n",
    ").astype(int)\n",
    "# High heart rate criteria (HR > 150 bpm)\n",
    "final_df['red_pulse_high_flag'] = (final_df['max_heart_rate'] > 150).astype(int)\n",
    "# Low heart rate criteria (HR < 40 bpm)\n",
    "final_df['red_pulse_low_flag'] = (final_df['min_heart_rate'] < 40).astype(int)\n",
    "\n",
    "# Yellow Respiratory Criteria\n",
    "final_df['yellow_resp_spo2_flag'] = (final_df['min_spo2'] >= 90).astype(int)\n",
    "final_df['yellow_fio2_flag'] = (final_df['min_fio2_set'] > 0.6).astype(int)\n",
    "final_df['yellow_resp_rate_flag'] = (final_df['max_resp_rate_obs'] > 30).astype(int)\n",
    "final_df['yellow_peep_flag'] = (final_df['min_peep_set'] > 10).astype(int)\n",
    "\n",
    "# Yellow Cardiovascular Criteria\n",
    "final_df['yellow_map_flag'] = (final_df['min_map'] >= 65).astype(int) & (final_df['ne_calc_max'].between(0.1, 0.3)).astype(int)\n",
    "final_df['yellow_pulse_flag'] = (final_df['min_heart_rate'].between(120, 150)).astype(int)\n",
    "final_df['yellow_lactate_flag'] = (final_df['lactate'] > 4).astype(int)\n",
    "\n",
    "# Step 3: Implement Green Criteria\n",
    "final_df['green_resp_spo2_flag'] = (final_df['min_spo2'] >= 90).astype(int)\n",
    "final_df['green_resp_rate_flag'] = (final_df['max_resp_rate_obs'] <= 30).astype(int)\n",
    "final_df['green_fio2_flag'] = (final_df['min_fio2_set'] <= 0.6).astype(int)\n",
    "final_df['green_peep_flag'] = (final_df['min_peep_set'] <= 10).astype(int)\n",
    "\n",
    "# Green Cardiovascular Criteria\n",
    "final_df['green_map_flag'] = (final_df['min_map'] >= 65).astype(int) & (final_df['ne_calc_max'] < 0.1).astype(int)\n",
    "final_df['green_pulse_flag'] = (final_df['min_heart_rate'] < 120).astype(int)\n",
    "final_df['green_lactate_flag'] = (final_df['lactate'] < 4).astype(int)\n",
    "final_df['green_hr_flag'] = (final_df['min_heart_rate'] > 40).astype(int)\n",
    "\n",
    "final_df['any_red'] = (\n",
    "    final_df['red_resp_spo2_flag'] |\n",
    "    final_df['red_map_flag'] |\n",
    "    final_df['red_high_support_flag'] |\n",
    "    final_df['red_hypertensive_flag'] |\n",
    "    final_df['red_pulse_high_flag'] |\n",
    "    final_df['red_pulse_low_flag']\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_yellow'] = (\n",
    "    (\n",
    "        final_df['yellow_resp_spo2_flag'] |\n",
    "        final_df['yellow_fio2_flag'] |\n",
    "        final_df['yellow_resp_rate_flag'] |\n",
    "        final_df['yellow_peep_flag'] |\n",
    "        final_df['yellow_map_flag'] |\n",
    "        final_df['yellow_pulse_flag'] |\n",
    "        final_df['yellow_lactate_flag']\n",
    "    )\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_green'] = (\n",
    "    final_df['green_resp_spo2_flag'] |\n",
    "    final_df['green_resp_rate_flag'] |\n",
    "    final_df['green_fio2_flag'] |\n",
    "    final_df['green_peep_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag'] \n",
    ").astype(int)\n",
    "\n",
    "\n",
    "final_df['all_green'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] \n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green_no_red'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['any_red'] == 0)  # Ensure no red subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green_no_red_yellow'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['any_red'] == 0)  & # Ensure no red subcomponents are met\n",
    "    (final_df['any_yellow'] == 0)  # Ensure no yellow subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# Define 'all_yellow_only' (all yellow subcomponents must be met, no red subcomponents, and no green subcomponents)\n",
    "final_df['all_yellow_no_red_green'] = (\n",
    "    final_df['yellow_resp_spo2_flag'] &\n",
    "    final_df['yellow_fio2_flag'] &\n",
    "    final_df['yellow_resp_rate_flag'] &\n",
    "    final_df['yellow_peep_flag'] &\n",
    "    final_df['yellow_map_flag'] &\n",
    "    final_df['yellow_pulse_flag'] &\n",
    "    final_df['yellow_lactate_flag'] &\n",
    "    (final_df['any_red'] == 0) &  # Ensure no red subcomponents are met\n",
    "    (final_df['any_green'] == 0)  # Ensure no green subcomponents are fully met\n",
    ").astype(int)\n",
    "\n",
    "#  Define 'any_yellow_only' (any yellow subcomponent is met, no green or red subcomponents are met)\n",
    "final_df['any_yellow_no_red_green'] = (\n",
    "    (\n",
    "        final_df['yellow_resp_spo2_flag'] |\n",
    "        final_df['yellow_fio2_flag'] |\n",
    "        final_df['yellow_resp_rate_flag'] |\n",
    "        final_df['yellow_peep_flag'] |\n",
    "        final_df['yellow_map_flag'] |\n",
    "        final_df['yellow_pulse_flag'] |\n",
    "        final_df['yellow_lactate_flag']\n",
    "    ) &\n",
    "    (final_df['any_red'] == 0) &  # Ensure no red subcomponents are met\n",
    "    (final_df['any_green'] == 0)  # Ensure no green subcomponents are fully met\n",
    ").astype(int)\n",
    "\n",
    "# Define 'any_yellow_or_green' (any yellow or green subcomponent is met, but no red subcomponents are met)\n",
    "final_df['any_yellow_or_green_no_red'] = (\n",
    "    (\n",
    "        final_df['yellow_resp_spo2_flag'] |\n",
    "        final_df['yellow_fio2_flag'] |\n",
    "        final_df['yellow_resp_rate_flag'] |\n",
    "        final_df['yellow_peep_flag'] |\n",
    "        final_df['yellow_map_flag'] |\n",
    "        final_df['yellow_pulse_flag'] |\n",
    "        final_df['yellow_lactate_flag'] |\n",
    "        final_df['green_resp_spo2_flag'] |\n",
    "        final_df['green_resp_rate_flag'] |\n",
    "        final_df['green_fio2_flag'] |\n",
    "        final_df['green_peep_flag'] |\n",
    "        final_df['green_map_flag'] |\n",
    "        final_df['green_pulse_flag'] |\n",
    "        final_df['green_lactate_flag'] |\n",
    "        final_df['green_hr_flag']\n",
    "    ) &\n",
    "    (final_df['any_red'] == 0)   # Ensure no red subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_resp_flag'] = (\n",
    "    (\n",
    "     final_df['yellow_resp_spo2_flag'] |\n",
    "     final_df['yellow_fio2_flag'] |\n",
    "     final_df['yellow_resp_rate_flag'] |\n",
    "     final_df['yellow_peep_flag'] |\n",
    "     final_df['green_resp_spo2_flag'] |\n",
    "     final_df['green_resp_rate_flag'] |\n",
    "     final_df['green_fio2_flag'] |\n",
    "     final_df['green_peep_flag'] \n",
    "    )  &\n",
    "    (final_df['any_red'] == 0)  # Ensure no red subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_cardio_flag'] = (\n",
    "    (\n",
    "    final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag']\n",
    "    )&\n",
    "    (final_df['any_red'] == 0)  # Ensure no red subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "# Group where all green subcomponents are met and no red or yellow criteria are met\n",
    "final_df['yellow_all_green'] = (\n",
    "    final_df['all_green_no_red'] &  # All green subcomponents are met with no red\n",
    "    (final_df['any_yellow'] == 0)   # Ensure no yellow subcomponents are met\n",
    ").astype(int)\n",
    "\n",
    "# Group where 'any_yellow_or_green_no_red' is met, but it's not all green (some yellow components are met)\n",
    "final_df['yellow_not_all_green'] = (\n",
    "    final_df['any_yellow_or_green_no_red'] &  # Meets the yellow or green criteria with no red\n",
    "    (final_df['all_green_no_red'] == 0)       # Ensure it does not meet all green criteria\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: To summarize the results, you can print value counts for each flag\n",
    "print(final_df[['any_red', 'any_yellow', 'any_green' ,  'all_green',\n",
    "                'all_green_no_red', 'all_green_no_red_yellow', 'all_yellow_no_red_green', \n",
    "                'any_yellow_no_red_green','any_yellow_or_green_no_red','yellow_all_green',\n",
    "                 'yellow_not_all_green' ]].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pyCLIF.load_data('clif_patient')\n",
    "hospitalization = pyCLIF.load_data('clif_hospitalization')\n",
    "patient = pyCLIF.remove_duplicates(patient, ['patient_id'], 'patient')\n",
    "hospitalization = pyCLIF.remove_duplicates(hospitalization, ['hospitalization_id'], 'hospitalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['hospitalization_id','recorded_date', 'recorded_hour', \n",
    "                   'patel_flag', 'team_flag', 'any_yellow_or_green_no_red',\n",
    "                   'ne_calc_min', 'max_peep_set', 'min_fio2_set']\n",
    "final_df_table1 = final_df[columns_to_keep]\n",
    "final_df_table1 = pd.merge(final_df_table1, hospitalization, how = 'left' , on='hospitalization_id')\n",
    "final_df_table1 = pd.merge(final_df_table1, patient, how = 'left' , on='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_table1.value_counts('race_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## confirm mapping here\n",
    "final_df_table1 = pyCLIF.map_race_column(final_df_table1, 'race_category')\n",
    "final_df_table1.value_counts('race_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to include in the table\n",
    "# Categorical variables\n",
    "categorical = ['sex_category', 'race_new']\n",
    "\n",
    "# Continuous variables\n",
    "continuous = ['age_at_admission']\n",
    "\n",
    "# If you have 'ne_calc_min', 'max_peep_set', 'min_fio2_set' in your dataframe, include them\n",
    "# For the sake of completeness, I'll assume these variables are present\n",
    "# If they are not, you can exclude them or replace them with the correct variable names\n",
    "additional_continuous = ['ne_calc_min', 'max_peep_set', 'min_fio2_set']\n",
    "\n",
    "# Check if these additional variables are in your DataFrame\n",
    "variables_to_check = additional_continuous\n",
    "variables_present = [var for var in variables_to_check if var in final_df_table1.columns]\n",
    "\n",
    "# Update the continuous variables list\n",
    "continuous += variables_present\n",
    "\n",
    "# All variables to include in the table\n",
    "columns = categorical + continuous\n",
    "\n",
    "# Create subsets based on criteria\n",
    "result_patel = final_df_table1[final_df_table1['patel_flag'] == 1].copy()\n",
    "result_team = final_df_table1[final_df_table1['team_flag'] == 1].copy()\n",
    "result_yellow = final_df_table1[final_df_table1['any_yellow_or_green_no_red'] == 1].copy()\n",
    "\n",
    "# Add a 'Criteria' column to each subset\n",
    "result_patel['Criteria'] = 'Patel Criteria'\n",
    "result_team['Criteria'] = 'TEAM Criteria'\n",
    "result_yellow['Criteria'] = 'Yellow Criteria'\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat([final_df_table1, result_patel, result_team, result_yellow], ignore_index=True)\n",
    "\n",
    "# Remove duplicates to ensure each hospitalization_id appears only once per criteria\n",
    "combined_df = combined_df.drop_duplicates(subset=['hospitalization_id', 'Criteria'])\n",
    "\n",
    "# Now, create the TableOne object\n",
    "table1 = TableOne(\n",
    "    combined_df,\n",
    "    columns=columns,\n",
    "    categorical=categorical,\n",
    "    groupby='Criteria',\n",
    "    pval=False,\n",
    "    missing=False\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "# print(table1.tabulate(tablefmt=\"fancy_grid\"))\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrict to business hours in the first 72 hours after intubation*\n",
    "\n",
    "* 4-hour cool off period after first intubation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: `time_from_vent_adjusted` is -1 until hour 4, then it counts up from 0. This builds in the 4-hour cool off period.\n",
    "business_hours_df = final_df[(final_df['time_from_vent_adjusted'] >= 0) & (final_df['time_from_vent_adjusted'] < 72)]\n",
    "#business_hours_df = final_df[(final_df['time_from_vent'] >= 0) & (final_df['time_from_vent'] < 72)]\n",
    "\n",
    "# recorded_hour is the hour of the day (0-23), so business hours are 8 (8 AM) - 17 (5 PM).\n",
    "business_hours_df = business_hours_df[(business_hours_df['recorded_hour'] >= 8) & (business_hours_df['recorded_hour'] < 17)].copy()\n",
    "business_hours_df['time_biz'] = business_hours_df.groupby('hospitalization_id').cumcount()\n",
    "\n",
    "business_hours_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final figures and tables\n",
    "\n",
    "1. Figure 1: Percentage of encounter satisfying Patel, TEAM, and any yellow or GREEN criteria\n",
    "2. Figure 2: Percentage of business hours each encounter was eligible for different criteria\n",
    "3. Figure 3: Percentage of business hours not eligible for each criteria broken down by subcomponent failure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligibility by encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_encounters_meeting_criteria(df):\n",
    "    total_encounters = df['hospitalization_id'].nunique()  # Calculate total unique encounters\n",
    "    # For each encounter, check if they ever met the criteria and sum up\n",
    "    criteria_counts = df.groupby('hospitalization_id').agg(\n",
    "        patel_met=('patel_flag', lambda x: x.max()),\n",
    "        team_met=('team_flag', lambda x: x.max()),\n",
    "        any_yellow_or_green_no_red_met=('any_yellow_or_green_no_red', lambda x: x.max())\n",
    "    ).sum().reset_index()\n",
    "\n",
    "    criteria_counts.columns = ['Criteria', 'Number of Encounters']\n",
    "    criteria_counts['Percentage'] = (criteria_counts['Number of Encounters'] / total_encounters) * 100\n",
    "    \n",
    "    return criteria_counts\n",
    "\n",
    "# Generate the criteria comparison table\n",
    "\n",
    "criteria_comparison_table = count_encounters_meeting_criteria(business_hours_df)\n",
    "criteria_comparison_table['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(criteria_comparison_table).to_csv(f'../output/final/eligibility_by_hosp_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "criteria_comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the criteria for clarity\n",
    "criteria_comparison_table['Criteria'] = criteria_comparison_table['Criteria'].replace({\n",
    "    'patel_met': 'Patel',\n",
    "    'team_met': 'TEAM',\n",
    "    'any_yellow_or_green_no_red_met': 'Yellow'\n",
    "})\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#983232', '#003f5c', '#fdfd96']  # Maroon, Dark Blue, Pastel Yellow\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(x='Criteria', y='Percentage', data=criteria_comparison_table, palette=custom_colors)\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in criteria_comparison_table.iterrows():\n",
    "    barplot.text(index, row['Percentage'] + 0.5, f\"{row['Percentage']:.1f}%\", \n",
    "                 color='black', ha=\"center\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Encounters')\n",
    "# plt.title('Percentage of Encounters Meeting Each Criterion')a\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligibility by business hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the percentage of business hours\n",
    "def compute_percentage_hours_by_criteria(df, criteria_columns):\n",
    "    \"\"\"\n",
    "    Compute the percentage of business hours each encounter was eligible for different criteria.\n",
    "    \"\"\"\n",
    "    # Calculate the total number of business hours per encounter\n",
    "    total_business_hours = df.groupby('hospitalization_id')['time_biz'].max()\n",
    "    # Filter out encounters with zero business hours to avoid division by zero\n",
    "    total_business_hours = total_business_hours[total_business_hours > 0]\n",
    "    # Sum the number of hours each criterion is met for each encounter\n",
    "    hours_criteria = df.groupby('hospitalization_id').agg({criterion: 'sum' for criterion in criteria_columns})\n",
    "    # Retain only the encounters with non-zero business hours\n",
    "    hours_criteria = hours_criteria.loc[total_business_hours.index]\n",
    "    # Calculate the percentage of business hours met for each criterion\n",
    "    percentage_hours_by_criteria = hours_criteria.divide(total_business_hours, axis=0) * 100\n",
    "    # Calculate the mean percentage of hours met for each criterion across all encounters\n",
    "    avg_percentage_by_criteria = percentage_hours_by_criteria.mean().reset_index()\n",
    "    avg_percentage_by_criteria.columns = ['Criteria', 'Average Percentage of Hours Met']\n",
    "    return avg_percentage_by_criteria\n",
    "\n",
    "# Define the mapping for the criteria\n",
    "criteria_columns = ['patel_flag', 'team_flag', 'any_yellow_or_green_no_red']\n",
    "criteria_mapping = {\n",
    "    'patel_flag': 'Patel',\n",
    "    'team_flag': 'TEAM',\n",
    "    'any_yellow_or_green_no_red': 'Yellow'\n",
    "}\n",
    "\n",
    "# Calculate the percentage of business hours met for each criterion\n",
    "avg_percentage_by_criteria = compute_percentage_hours_by_criteria(business_hours_df, criteria_columns)\n",
    "\n",
    "# Replace the criteria names according to the mapping\n",
    "avg_percentage_by_criteria['Criteria'] = avg_percentage_by_criteria['Criteria'].replace(criteria_mapping)\n",
    "avg_percentage_by_criteria['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(avg_percentage_by_criteria).to_csv(f'../output/final/eligibility_by_hour_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "avg_percentage_by_criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Custom colors for each criterion: Patel (Maroon), TEAM (Dark Blue), Yellow (Pastel Yellow)\n",
    "custom_colors = ['#983232', '#003366', '#fdfd96']\n",
    "\n",
    "ax = sns.barplot(x='Criteria', y='Average Percentage of Hours Met', data=avg_percentage_by_criteria, palette=custom_colors)\n",
    "\n",
    "# Add the percentage as labels on top of the bars\n",
    "for i, row in avg_percentage_by_criteria.iterrows():\n",
    "    ax.text(i, row['Average Percentage of Hours Met'] + 0.5, f'{row[\"Average Percentage of Hours Met\"]:.2f}%', \n",
    "            ha='center', color='black', fontsize=12)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Percentage of Business Hours Each Encounter Was Eligible for Different Criteria')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Average Percentage of Business Hours (%)')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure by subcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define your criteria and corresponding subcomponent flags\n",
    "criteria_info = {\n",
    "    'patel_flag': {'resp_flag': 'patel_resp_flag', 'cardio_flag': 'patel_cardio_flag'},\n",
    "    'team_flag': {'resp_flag': 'team_resp_flag', 'cardio_flag': 'team_cardio_flag'},\n",
    "    'any_yellow_or_green_no_red': {'resp_flag': 'yellow_resp_flag', 'cardio_flag': 'yellow_cardio_flag'}\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over each criterion\n",
    "for criterion, flags in criteria_info.items():\n",
    "    resp_flag = flags['resp_flag']\n",
    "    cardio_flag = flags['cardio_flag']\n",
    "    \n",
    "    # Calculate total hours per hospitalization_id\n",
    "    total_hours = final_df.groupby('hospitalization_id').size().rename('total_hours')\n",
    "    \n",
    "    # Create failure indicators\n",
    "    df_failure = final_df.copy()\n",
    "    df_failure['resp_only_failure'] = ((df_failure[resp_flag] == 0) & (df_failure[cardio_flag] == 1)).astype(int)\n",
    "    df_failure['cardio_only_failure'] = ((df_failure[resp_flag] == 1) & (df_failure[cardio_flag] == 0)).astype(int)\n",
    "    df_failure['both_failures'] = ((df_failure[resp_flag] == 0) & (df_failure[cardio_flag] == 0)).astype(int)\n",
    "    \n",
    "    # Aggregate the counts per hospitalization_id\n",
    "    failure_counts = df_failure.groupby('hospitalization_id')[['resp_only_failure', 'cardio_only_failure', 'both_failures']].sum()\n",
    "    \n",
    "    # Merge with total hours\n",
    "    failure_counts = failure_counts.merge(total_hours, left_index=True, right_index=True)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    failure_counts['resp_only_failure_perc'] = (failure_counts['resp_only_failure'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    failure_counts['cardio_only_failure_perc'] = (failure_counts['cardio_only_failure'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    failure_counts['both_failures_perc'] = (failure_counts['both_failures'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    \n",
    "    # Calculate total failure percentage\n",
    "    failure_counts['total_failure_perc'] = (\n",
    "        failure_counts['resp_only_failure'] + failure_counts['cardio_only_failure'] + failure_counts['both_failures']\n",
    "    ) * 100 / failure_counts['total_hours']\n",
    "    \n",
    "    # Calculate criterion met percentage\n",
    "    criterion_met = final_df.groupby('hospitalization_id')[criterion].sum().rename('criterion_met_hours')\n",
    "    failure_counts = failure_counts.merge(criterion_met, left_index=True, right_index=True)\n",
    "    failure_counts['criterion_met_perc'] = (failure_counts['criterion_met_hours'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    \n",
    "    # Add criterion name to the DataFrame\n",
    "    failure_counts['Criteria'] = criterion\n",
    "    \n",
    "    # Append to results\n",
    "    results.append(failure_counts.reset_index())\n",
    "\n",
    "# Concatenate results for all criteria\n",
    "all_failure_counts = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Now, calculate the average percentages across all hospitalizations for each criterion\n",
    "avg_failure_percentages = all_failure_counts.groupby('Criteria').agg({\n",
    "    'resp_only_failure_perc': 'mean',\n",
    "    'cardio_only_failure_perc': 'mean',\n",
    "    'both_failures_perc': 'mean',\n",
    "    'total_failure_perc': 'mean',\n",
    "    'criterion_met_perc': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "avg_failure_percentages = avg_failure_percentages.rename(columns={\n",
    "    'resp_only_failure_perc': 'Resp Failure Only',\n",
    "    'cardio_only_failure_perc': 'Cardio Failure Only',\n",
    "    'both_failures_perc': 'Both Failures',\n",
    "    'total_failure_perc': 'Total Failure',\n",
    "    'criterion_met_perc': 'Criterion Met'\n",
    "})\n",
    "\n",
    "# Display the average failure percentages\n",
    "criteria_mapping = {\n",
    "    'patel_flag': 'Patel',\n",
    "    'team_flag': 'TEAM',\n",
    "    'any_yellow_or_green_no_red': 'Yellow'\n",
    "}\n",
    "\n",
    "avg_failure_percentages['Criteria'] = avg_failure_percentages['Criteria'].replace(criteria_mapping)\n",
    "avg_failure_percentages['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(avg_failure_percentages).to_csv(f'../output/final/avg_failure_percentages_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "avg_failure_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for each criterion\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Criterion Met'],\n",
    "    marker=dict(color=avg_failure_percentages['Criteria'].map({\n",
    "        'Yellow': '#fdfd96',\n",
    "        'Patel': '#983232',\n",
    "        'TEAM': '#003366'\n",
    "    })),  # Custom colors\n",
    "    text=avg_failure_percentages['Criterion Met'].round(2),\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    # title='Average Percentage of Business Hours Each Criterion Is Met',\n",
    "    xaxis_title='Criteria',\n",
    "    yaxis_title='Average Percentage of Business Hours Met (%)',\n",
    "    yaxis=dict(range=[0, 100]),  # Ensure y-axis range is 0-100%\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stacked bar plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for Cardio Failure Only\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Cardio Failure Only'],\n",
    "    name='Cardio Failure Only',\n",
    "    marker_color='#003366'  # Dark Blue\n",
    "))\n",
    "\n",
    "# Add bars for Resp Failure Only\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Resp Failure Only'],\n",
    "    name='Resp Failure Only',\n",
    "    marker_color='#983232'  # Maroon\n",
    "))\n",
    "\n",
    "# Add bars for Both Failures\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Both Failures'],\n",
    "    name='Both Failures',\n",
    "    marker_color='#fdfd96'  # Pastel Yellow\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis_title='Criteria',\n",
    "    yaxis_title='Average Percentage of Business Hours Not Met (%)',\n",
    "    yaxis=dict(range=[0, 100]),\n",
    "    template='plotly_white',\n",
    "    legend_title='Failure Type'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to eligibility from intubation\n",
    "\n",
    "This analysis includes a 4 hour \"cool off\" period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the Patel criteria are met\n",
    "patel_eligible_df = business_hours_df[business_hours_df['patel_flag'] == 1]\n",
    "\n",
    "# Find the first time each patient meets the Patel criteria\n",
    "first_eligibility_times_patel = patel_eligible_df.groupby('hospitalization_id')['time_from_vent'].min().reset_index()\n",
    "\n",
    "# Create the survival analysis dataset\n",
    "survival_analysis_df_patel = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "\n",
    "# Merge with the first eligibility times\n",
    "survival_analysis_df_patel = pd.merge(survival_analysis_df_patel, first_eligibility_times_patel, on='hospitalization_id', how='left')\n",
    "\n",
    "# Fill NaN values with 27 for patients who were never eligible\n",
    "survival_analysis_df_patel['time_from_vent'] = survival_analysis_df_patel['time_from_vent'].fillna(27)\n",
    "\n",
    "# Create the 'eligible' column\n",
    "survival_analysis_df_patel['eligible'] = (survival_analysis_df_patel['time_from_vent'] != 27).astype(int)\n",
    "\n",
    "# Rename columns\n",
    "survival_analysis_df_patel.rename(columns={'time_from_vent': 'time_to_first_eligibility'}, inplace=True)\n",
    "\n",
    "# Add +1 to time_to_first_eligibility\n",
    "survival_analysis_df_patel['time_to_first_eligibility'] = survival_analysis_df_patel['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Display the final dataset\n",
    "print(survival_analysis_df_patel.head())\n",
    "\n",
    "# Repeat the process for TEAM criteria\n",
    "team_eligible_df = business_hours_df[business_hours_df['team_flag'] == 1]\n",
    "first_eligibility_times_team = team_eligible_df.groupby('hospitalization_id')['time_from_vent'].min().reset_index()\n",
    "survival_analysis_df_team = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "survival_analysis_df_team = pd.merge(survival_analysis_df_team, first_eligibility_times_team, on='hospitalization_id', how='left')\n",
    "survival_analysis_df_team['time_from_vent'] = survival_analysis_df_team['time_from_vent'].fillna(27)\n",
    "survival_analysis_df_team['eligible'] = (survival_analysis_df_team['time_from_vent'] != 27).astype(int)\n",
    "survival_analysis_df_team.rename(columns={'time_from_vent': 'time_to_first_eligibility'}, inplace=True)\n",
    "survival_analysis_df_team['time_to_first_eligibility'] = survival_analysis_df_team['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Repeat the process for Yellow criteria\n",
    "yellow_eligible_df = business_hours_df[business_hours_df['any_yellow_or_green_no_red'] == 1]\n",
    "first_eligibility_times_yellow = yellow_eligible_df.groupby('hospitalization_id')['time_from_vent'].min().reset_index()\n",
    "survival_analysis_df_yellow = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "survival_analysis_df_yellow = pd.merge(survival_analysis_df_yellow, first_eligibility_times_yellow, on='hospitalization_id', how='left')\n",
    "survival_analysis_df_yellow['time_from_vent'] = survival_analysis_df_yellow['time_from_vent'].fillna(27)\n",
    "survival_analysis_df_yellow['eligible'] = (survival_analysis_df_yellow['time_from_vent'] != 27).astype(int)\n",
    "survival_analysis_df_yellow.rename(columns={'time_from_vent': 'time_to_first_eligibility'}, inplace=True)\n",
    "survival_analysis_df_yellow['time_to_first_eligibility'] = survival_analysis_df_yellow['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Display the final datasets\n",
    "print(survival_analysis_df_team.head())\n",
    "print(survival_analysis_df_yellow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Initialize the KaplanMeierFitter for Patel, TEAM and Yellow criteria\n",
    "kmf_patel = KaplanMeierFitter()\n",
    "kmf_team = KaplanMeierFitter()\n",
    "kmf_yellow = KaplanMeierFitter()\n",
    "\n",
    "# fit the data for Patel criteria\n",
    "kmf_patel.fit(durations=survival_analysis_df_patel['time_to_first_eligibility'], event_observed=survival_analysis_df_patel['eligible'], label='Patel Criteria')\n",
    "\n",
    "# Fit the data for TEAM criteria\n",
    "kmf_team.fit(durations=survival_analysis_df_team['time_to_first_eligibility'], event_observed=survival_analysis_df_team['eligible'], label='TEAM Criteria')\n",
    "\n",
    "# Fit the data for Yellow criteria\n",
    "kmf_yellow.fit(durations=survival_analysis_df_yellow['time_to_first_eligibility'], event_observed=survival_analysis_df_yellow['eligible'], label='Yellow Criteria')\n",
    "\n",
    "# Plot the cumulative incidence function for all criteria\n",
    "ax = kmf_patel.plot_cumulative_density()\n",
    "kmf_team.plot_cumulative_density(ax=ax)\n",
    "kmf_yellow.plot_cumulative_density(ax=ax)\n",
    "\n",
    "plt.title('Cumulative Incidence Function for Time to First Eligibility')\n",
    "plt.xlabel('Time to First Eligibility from Intubation (hours)')\n",
    "plt.ylabel('Cumulative Incidence Probability')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Estimate the median time to first eligibility for all criteria\n",
    "median_time_to_first_eligibility_patel = kmf_patel.median_survival_time_\n",
    "median_time_to_first_eligibility_team = kmf_team.median_survival_time_\n",
    "median_time_to_first_eligibility_yellow = kmf_yellow.median_survival_time_\n",
    "\n",
    "print(f\"Median time to first eligibility (Patel): {median_time_to_first_eligibility_patel} hours\")\n",
    "print(f\"Median time to first eligibility (TEAM): {median_time_to_first_eligibility_team} hours\")\n",
    "print(f\"Median time to first eligibility (Yellow): {median_time_to_first_eligibility_yellow} hours\")\n",
    "\n",
    "# Calculate the cumulative incidence function value at time = 1 for all criteria\n",
    "cif_value_at_1_patel = 1 - kmf_patel.predict(1)\n",
    "cif_value_at_1_team = 1 - kmf_team.predict(1)\n",
    "cif_value_at_1_yellow = 1 - kmf_yellow.predict(1)\n",
    "\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (Patel): {cif_value_at_1_patel:.0%}\")\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (TEAM): {cif_value_at_1_team:.0%}\")\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (Yellow): {cif_value_at_1_yellow:.0%}\")\n",
    "\n",
    "\n",
    "# Save the cumulative incidence function data to CSV files\n",
    "cif_patel = kmf_patel.cumulative_density_.reset_index()\n",
    "cif_team = kmf_team.cumulative_density_.reset_index()\n",
    "cif_yellow = kmf_yellow.cumulative_density_.reset_index()\n",
    "\n",
    "# Add a column to identify the criteria\n",
    "cif_patel['Criteria'] = 'Patel'\n",
    "cif_team['Criteria'] = 'TEAM'\n",
    "cif_yellow['Criteria'] = 'Yellow'\n",
    "\n",
    "\n",
    "# Get the site name from pyCLIF helper\n",
    "site_name = pyCLIF.helper[\"site_name\"]\n",
    "\n",
    "cif_patel['Site'] = site_name\n",
    "cif_team['Site'] = site_name\n",
    "cif_yellow['Site'] = site_name\n",
    "\n",
    "# Save to CSV files with site name in the file names\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "cif_patel.to_csv(f'../output/final/cif_patel_{site_name}_{timestamp}.csv', index=False)\n",
    "cif_team.to_csv(f'../output/final/cif_team_{site_name}_{timestamp}.csv', index=False)\n",
    "cif_yellow.to_csv(f'../output/final/cif_yellow_{site_name}_{timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the Patel criteria are met\n",
    "patel_eligible_df = business_hours_df[business_hours_df['patel_flag'] == 1]\n",
    "\n",
    "# Find the first time each patient meets the Patel criteria\n",
    "first_eligibility_times_patel = patel_eligible_df.groupby('hospitalization_id')['time_biz'].min().reset_index()\n",
    "\n",
    "# Create the survival analysis dataset\n",
    "survival_analysis_df_patel = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "\n",
    "# Merge with the first eligibility times\n",
    "survival_analysis_df_patel = pd.merge(survival_analysis_df_patel, first_eligibility_times_patel, on='hospitalization_id', how='left')\n",
    "\n",
    "# Fill NaN values with 27 for patients who were never eligible\n",
    "survival_analysis_df_patel['time_biz'] = survival_analysis_df_patel['time_biz'].fillna(27)\n",
    "\n",
    "# Create the 'eligible' column\n",
    "survival_analysis_df_patel['eligible'] = (survival_analysis_df_patel['time_biz'] != 27).astype(int)\n",
    "\n",
    "# Rename columns\n",
    "survival_analysis_df_patel.rename(columns={'time_biz': 'time_to_first_eligibility'}, inplace=True)\n",
    "\n",
    "# Add +1 to time_to_first_eligibility\n",
    "survival_analysis_df_patel['time_to_first_eligibility'] = survival_analysis_df_patel['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Display the final dataset\n",
    "print(survival_analysis_df_patel.head())\n",
    "\n",
    "# Repeat the process for TEAM criteria\n",
    "team_eligible_df = business_hours_df[business_hours_df['team_flag'] == 1]\n",
    "first_eligibility_times_team = team_eligible_df.groupby('hospitalization_id')['time_biz'].min().reset_index()\n",
    "survival_analysis_df_team = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "survival_analysis_df_team = pd.merge(survival_analysis_df_team, first_eligibility_times_team, on='hospitalization_id', how='left')\n",
    "survival_analysis_df_team['time_biz'] = survival_analysis_df_team['time_biz'].fillna(27)\n",
    "survival_analysis_df_team['eligible'] = (survival_analysis_df_team['time_biz'] != 27).astype(int)\n",
    "survival_analysis_df_team.rename(columns={'time_biz': 'time_to_first_eligibility'}, inplace=True)\n",
    "survival_analysis_df_team['time_to_first_eligibility'] = survival_analysis_df_team['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Repeat the process for Yellow criteria\n",
    "yellow_eligible_df = business_hours_df[business_hours_df['any_yellow_or_green_no_red'] == 1]\n",
    "first_eligibility_times_yellow = yellow_eligible_df.groupby('hospitalization_id')['time_biz'].min().reset_index()\n",
    "survival_analysis_df_yellow = business_hours_df[['hospitalization_id']].drop_duplicates().copy()\n",
    "survival_analysis_df_yellow = pd.merge(survival_analysis_df_yellow, first_eligibility_times_yellow, on='hospitalization_id', how='left')\n",
    "survival_analysis_df_yellow['time_biz'] = survival_analysis_df_yellow['time_biz'].fillna(27)\n",
    "survival_analysis_df_yellow['eligible'] = (survival_analysis_df_yellow['time_biz'] != 27).astype(int)\n",
    "survival_analysis_df_yellow.rename(columns={'time_biz': 'time_to_first_eligibility'}, inplace=True)\n",
    "survival_analysis_df_yellow['time_to_first_eligibility'] = survival_analysis_df_yellow['time_to_first_eligibility'] + 1\n",
    "\n",
    "# Display the final datasets\n",
    "print(survival_analysis_df_team.head())\n",
    "print(survival_analysis_df_yellow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KaplanMeierFitter for Patel, TEAM and Yellow criteria\n",
    "kmf_patel = KaplanMeierFitter()\n",
    "kmf_team = KaplanMeierFitter()\n",
    "kmf_yellow = KaplanMeierFitter()\n",
    "\n",
    "# fit the data for Patel criteria\n",
    "kmf_patel.fit(durations=survival_analysis_df_patel['time_to_first_eligibility'], event_observed=survival_analysis_df_patel['eligible'], label='Patel Criteria')\n",
    "\n",
    "# Fit the data for TEAM criteria\n",
    "kmf_team.fit(durations=survival_analysis_df_team['time_to_first_eligibility'], event_observed=survival_analysis_df_team['eligible'], label='TEAM Criteria')\n",
    "\n",
    "# Fit the data for Yellow criteria\n",
    "kmf_yellow.fit(durations=survival_analysis_df_yellow['time_to_first_eligibility'], event_observed=survival_analysis_df_yellow['eligible'], label='Yellow Criteria')\n",
    "\n",
    "# Plot the cumulative incidence function for all criteria\n",
    "ax = kmf_patel.plot_cumulative_density()\n",
    "kmf_team.plot_cumulative_density(ax=ax)\n",
    "kmf_yellow.plot_cumulative_density(ax=ax)\n",
    "\n",
    "plt.title('Cumulative Incidence Function for Time to First Eligibility')\n",
    "plt.xlabel('Time to First Eligibility (business hours)')\n",
    "plt.ylabel('Cumulative Incidence Probability')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Estimate the median time to first eligibility for all criteria\n",
    "median_time_to_first_eligibility_patel = kmf_patel.median_survival_time_\n",
    "median_time_to_first_eligibility_team = kmf_team.median_survival_time_\n",
    "median_time_to_first_eligibility_yellow = kmf_yellow.median_survival_time_\n",
    "\n",
    "print(f\"Median time to first eligibility (Patel): {median_time_to_first_eligibility_patel} hours\")\n",
    "print(f\"Median time to first eligibility (TEAM): {median_time_to_first_eligibility_team} hours\")\n",
    "print(f\"Median time to first eligibility (Yellow): {median_time_to_first_eligibility_yellow} hours\")\n",
    "\n",
    "# Calculate the cumulative incidence function value at time = 1 for all criteria\n",
    "cif_value_at_1_patel = 1 - kmf_patel.predict(1)\n",
    "cif_value_at_1_team = 1 - kmf_team.predict(1)\n",
    "cif_value_at_1_yellow = 1 - kmf_yellow.predict(1)\n",
    "\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (Patel): {cif_value_at_1_patel:.0%}\")\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (TEAM): {cif_value_at_1_team:.0%}\")\n",
    "print(f\"Cumulative Incidence Function value at time = 1 (Yellow): {cif_value_at_1_yellow:.0%}\")\n",
    "\n",
    "\n",
    "# Save the cumulative incidence function data to CSV files\n",
    "cif_patel = kmf_patel.cumulative_density_.reset_index()\n",
    "cif_team = kmf_team.cumulative_density_.reset_index()\n",
    "cif_yellow = kmf_yellow.cumulative_density_.reset_index()\n",
    "\n",
    "# Add a column to identify the criteria\n",
    "cif_patel['Criteria'] = 'Patel'\n",
    "cif_team['Criteria'] = 'TEAM'\n",
    "cif_yellow['Criteria'] = 'Yellow'\n",
    "\n",
    "\n",
    "# Get the site name from pyCLIF helper\n",
    "site_name = pyCLIF.helper[\"site_name\"]\n",
    "\n",
    "cif_patel['Site'] = site_name\n",
    "cif_team['Site'] = site_name\n",
    "cif_yellow['Site'] = site_name\n",
    "\n",
    "# Save to CSV files with site name in the file names\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "cif_patel.to_csv(f'../output/final/cif_b_hours_patel_{site_name}_{timestamp}.csv', index=False)\n",
    "cif_team.to_csv(f'../output/final/cif_b_hours_team_{site_name}_{timestamp}.csv', index=False)\n",
    "cif_yellow.to_csv(f'../output/final/cif_b_hours_yellow_{site_name}_{timestamp}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mobilization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
